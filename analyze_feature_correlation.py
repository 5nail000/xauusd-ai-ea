"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Ñ–∏—á–µ–π –∏ —É–¥–∞–ª–µ–Ω–∏—è –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö
"""
import pandas as pd
import numpy as np
import argparse
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import List, Tuple, Set

# –ó–∞—â–∏—â–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ - –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —É–¥–∞–ª—è—é—Ç—Å—è
PROTECTED_FEATURES = ['open', 'high', 'low', 'close']

def find_highly_correlated_pairs(df: pd.DataFrame, 
                                 feature_columns: List[str],
                                 threshold: float = 0.95) -> List[Tuple[str, str, float]]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –ø–∞—Ä—ã —Ñ–∏—á–µ–π —Å –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π
    
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        feature_columns: –°–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫-—Ñ–∏—á–µ–π
        threshold: –ü–æ—Ä–æ–≥ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.95)
    
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (feature1, feature2, correlation)
    """
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É
    corr_matrix = df[feature_columns].corr()
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä—ã
    high_corr_pairs = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            corr_value = corr_matrix.iloc[i, j]
            if abs(corr_value) > threshold:
                high_corr_pairs.append((
                    corr_matrix.columns[i],
                    corr_matrix.columns[j],
                    corr_value
                ))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    high_corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)
    
    return high_corr_pairs

def select_features_to_remove(high_corr_pairs: List[Tuple[str, str, float]],
                               feature_columns: List[str]) -> Set[str]:
    """
    –í—ã–±–∏—Ä–∞–µ—Ç —Ñ–∏—á–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä
    
    –°—Ç—Ä–∞—Ç–µ–≥–∏—è: —É–¥–∞–ª—è–µ–º –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –∏–ª–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —Ñ–∏—á–∏,
    –æ—Å—Ç–∞–≤–ª—è—è –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã–µ –∏ –±–∞–∑–æ–≤—ã–µ. –ë–∞–∑–æ–≤—ã–µ OHLC —Ü–µ–Ω—ã –∑–∞—â–∏—â–µ–Ω—ã.
    
    Args:
        high_corr_pairs: –°–ø–∏—Å–æ–∫ –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä
        feature_columns: –í—Å–µ —Ñ–∏—á–∏
    
    Returns:
        –ú–Ω–æ–∂–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    """
    features_to_remove = set()
    
    def is_protected(feature_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∏—á–∞ –∑–∞—â–∏—â–µ–Ω–Ω–æ–π (–±–∞–∑–æ–≤—ã–µ OHLC)"""
        return feature_name.lower() in [f.lower() for f in PROTECTED_FEATURES]
    
    def get_priority(feature_name: str) -> int:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Ñ–∏—á–∏ (–º–µ–Ω—å—à–µ = –≤—ã—à–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã:
        0 - –∑–∞—â–∏—â–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ (open, high, low, close)
        1 - –ø—Ä–æ—Å—Ç—ã–µ –±–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏ (sma, ema, rsi, macd, atr, momentum)
        2 - –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —Ñ–∏—á–∏ (close_rolling_mean, close_momentum, returns_rolling)
        3 - —Å–ª–æ–∂–Ω—ã–µ/–¥–ª–∏–Ω–Ω—ã–µ —Ñ–∏—á–∏ (price_sma_distance, close_rolling_median, multitimeframe)
        4 - lag —Ñ–∏—á–∏ (close_lag_1, close_lag_2, etc.)
        """
        feature_lower = feature_name.lower()
        
        # –ó–∞—â–∏—â–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ - –Ω–∞–∏–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        if is_protected(feature_name):
            return 0
        
        # –ü—Ä–æ—Å—Ç—ã–µ –±–∞–∑–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (–∫–æ—Ä–æ—Ç–∫–∏–µ –∏–º–µ–Ω–∞)
        simple_indicators = ['sma', 'ema', 'rsi', 'macd', 'atr', 'momentum', 'std', 'bb_']
        if any(ind in feature_lower for ind in simple_indicators) and len(feature_name) < 15:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è —Ñ–∏—á–∞
            if 'rolling' not in feature_lower and 'distance' not in feature_lower:
                return 1
        
        # Lag —Ñ–∏—á–∏ - –Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç (–º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å —á–∞—Å—Ç—å)
        if 'lag' in feature_lower:
            return 4
        
        # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —Ñ–∏—á–∏ (rolling, distance, etc.)
        if any(x in feature_lower for x in ['rolling', 'distance', 'position', 'zscore', 'percentile']):
            return 3
        
        # –°–ª–æ–∂–Ω—ã–µ/–¥–ª–∏–Ω–Ω—ã–µ –∏–º–µ–Ω–∞
        if len(feature_name) > 20:
            return 3
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        return 2
    
    def prefer_simple_name(feat1: str, feat2: str) -> str:
        """
        –í—ã–±–∏—Ä–∞–µ—Ç –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–µ –∏–º—è –∏–∑ –¥–≤—É—Ö
        –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è:
        1. –ë–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è
        2. –ú–µ–Ω—å—à–µ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–π
        3. –ë–æ–ª–µ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (sma > close_rolling_mean)
        """
        # –ï—Å–ª–∏ –æ–¥–Ω–æ –∏–º—è –Ω–∞–º–Ω–æ–≥–æ –∫–æ—Ä–æ—á–µ
        if len(feat1) < len(feat2) - 3:
            return feat1
        if len(feat2) < len(feat1) - 3:
            return feat2
        
        # –ï—Å–ª–∏ –¥–ª–∏–Ω—ã –ø–æ—Ö–æ–∂–∏, —Å—á–∏—Ç–∞–µ–º –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
        underscores1 = feat1.count('_')
        underscores2 = feat2.count('_')
        if underscores1 < underscores2:
            return feat1
        if underscores2 < underscores1:
            return feat2
        
        # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        feat1_lower = feat1.lower()
        feat2_lower = feat2.lower()
        
        # sma/ema –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–µ–µ close_rolling_mean
        if 'sma_' in feat1_lower or 'ema_' in feat1_lower:
            if 'rolling_mean' in feat2_lower:
                return feat1
        if 'sma_' in feat2_lower or 'ema_' in feat2_lower:
            if 'rolling_mean' in feat1_lower:
                return feat2
        
        # momentum –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–µ–µ close_momentum
        if feat1_lower == 'momentum' and 'close_momentum' in feat2_lower:
            return feat1
        if feat2_lower == 'momentum' and 'close_momentum' in feat1_lower:
            return feat2
        
        # price_to –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–µ–µ distance_to
        if 'price_to' in feat1_lower and 'distance_to' in feat2_lower:
            return feat1
        if 'price_to' in feat2_lower and 'distance_to' in feat1_lower:
            return feat2
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–±–∏—Ä–∞–µ–º –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–æ–µ
        return feat1 if len(feat1) <= len(feat2) else feat2
    
    for feat1, feat2, corr in high_corr_pairs:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –æ–¥–Ω–∞ –∏–∑ —Ñ–∏—á–µ–π —É–∂–µ –ø–æ–º–µ—á–µ–Ω–∞ –∫ —É–¥–∞–ª–µ–Ω–∏—é
        if feat1 in features_to_remove or feat2 in features_to_remove:
            continue
        
        # –ó–∞—â–∏—â–∞–µ–º –±–∞–∑–æ–≤—ã–µ OHLC —Ü–µ–Ω—ã - –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —É–¥–∞–ª—è–µ–º
        if is_protected(feat1):
            features_to_remove.add(feat2)
            continue
        if is_protected(feat2):
            features_to_remove.add(feat1)
            continue
        
        # –î–ª—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–¥–µ–Ω—Ç–∏—á–Ω—ã—Ö —Ñ–∏—á–µ–π (corr = 1.0) –≤—ã–±–∏—Ä–∞–µ–º –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–µ –∏–º—è
        if abs(corr) >= 0.99999:
            preferred = prefer_simple_name(feat1, feat2)
            if preferred == feat1:
                features_to_remove.add(feat2)
            else:
                features_to_remove.add(feat1)
            continue
        
        # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã
        priority1 = get_priority(feat1)
        priority2 = get_priority(feat2)
        
        if priority1 > priority2:
            features_to_remove.add(feat1)
        elif priority2 > priority1:
            features_to_remove.add(feat2)
        else:
            # –ï—Å–ª–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —Ä–∞–≤–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö –∏–º–µ–Ω
            preferred = prefer_simple_name(feat1, feat2)
            if preferred == feat1:
                features_to_remove.add(feat2)
            else:
                features_to_remove.add(feat1)
    
    return features_to_remove

def plot_correlation_matrix(df: pd.DataFrame, 
                           feature_columns: List[str],
                           save_path: str = None,
                           max_features: int = 50):
    """
    –°—Ç—Ä–æ–∏—Ç —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
    
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        feature_columns: –°–ø–∏—Å–æ–∫ —Ñ–∏—á–µ–π –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞
        max_features: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    """
    if len(feature_columns) > max_features:
        print(f"‚ö†Ô∏è  –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ñ–∏—á–µ–π ({len(feature_columns)}). –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ {max_features}")
        feature_columns = feature_columns[:max_features]
    
    corr_matrix = df[feature_columns].corr()
    
    plt.figure(figsize=(20, 16))
    sns.heatmap(corr_matrix, 
                annot=False, 
                cmap='coolwarm', 
                center=0,
                square=True,
                fmt='.2f',
                cbar_kws={'label': 'Correlation'})
    plt.title('Correlation Matrix of Features', fontsize=16, pad=20)
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"‚úì –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
    else:
        plt.show()
    
    plt.close()

def analyze_combined_datasets(train_path: str, val_path: str, test_path: str,
                              threshold: float = 0.95) -> Set[str]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –Ω–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ (train+val+test)
    –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    
    Args:
        train_path: –ü—É—Ç—å –∫ train CSV
        val_path: –ü—É—Ç—å –∫ val CSV
        test_path: –ü—É—Ç—å –∫ test CSV
        threshold: –ü–æ—Ä–æ–≥ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    
    Returns:
        –ú–Ω–æ–∂–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    """
    print("=" * 80)
    print("–ê–ù–ê–õ–ò–ó –ö–û–†–†–ï–õ–Ø–¶–ò–ò –ù–ê –û–ë–™–ï–î–ò–ù–ï–ù–ù–û–ú –î–ê–¢–ê–°–ï–¢–ï")
    print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Ç—Ä–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
    datasets = {}
    for name, path in [('train', train_path), ('val', val_path), ('test', test_path)]:
        if not Path(path).exists():
            print(f"‚ö†Ô∏è  –§–∞–π–ª {path} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º...")
            continue
        print(f"\n–ó–∞–≥—Ä—É–∑–∫–∞ {name} –¥–∞–Ω–Ω—ã—Ö –∏–∑ {path}...")
        datasets[name] = pd.read_csv(path, index_col=0, parse_dates=True)
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(datasets[name])} —Å—Ç—Ä–æ–∫, {len(datasets[name].columns)} –∫–æ–ª–æ–Ω–æ–∫")
    
    if not datasets:
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return set()
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
    print("\n–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")
    combined_df = pd.concat(datasets.values(), ignore_index=False)
    print(f"   –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {len(combined_df)} —Å—Ç—Ä–æ–∫, {len(combined_df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
    
    # –í—ã–±–æ—Ä —Ñ–∏—á–µ–π (–∏—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ)
    exclude_patterns = ['future_return', 'signal_class', 'signal_class_name', 'max_future_return']
    feature_columns = [
        col for col in combined_df.columns 
        if not any(pattern in col for pattern in exclude_patterns)
        and pd.api.types.is_numeric_dtype(combined_df[col])
    ]
    
    print(f"   –ù–∞–π–¥–µ–Ω–æ {len(feature_columns)} —Ñ–∏—á–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
    print("\n–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    nan_counts = combined_df[feature_columns].isna().sum()
    cols_with_nan = nan_counts[nan_counts > 0]
    if len(cols_with_nan) > 0:
        print(f"   ‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(cols_with_nan)} —Ñ–∏—á–µ–π —Å NaN –∑–Ω–∞—á–µ–Ω–∏—è–º–∏")
        print(f"   –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –º–µ–¥–∏–∞–Ω–æ–π...")
        combined_df[feature_columns] = combined_df[feature_columns].fillna(combined_df[feature_columns].median())
    else:
        print("   ‚úì NaN –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –Ω–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
    print(f"\n–ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –Ω–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ (–ø–æ—Ä–æ–≥: {threshold})...")
    high_corr_pairs = find_highly_correlated_pairs(combined_df, feature_columns, threshold)
    
    if len(high_corr_pairs) == 0:
        print(f"   ‚úì –í—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä (>{threshold}) –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return set()
    
    print(f"   –ù–∞–π–¥–µ–Ω–æ {len(high_corr_pairs)} –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä")
    
    # –í—ã–±–æ—Ä —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    print("\n–í—ã–±–æ—Ä —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è...")
    print(f"   –ó–∞—â–∏—â–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ (–Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —É–¥–∞–ª—è—é—Ç—Å—è): {', '.join(PROTECTED_FEATURES)}")
    features_to_remove = select_features_to_remove(high_corr_pairs, feature_columns)
    
    print(f"\n‚úì –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ {len(features_to_remove)} —Ñ–∏—á–µ–π –∏–∑ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤:")
    for feat in sorted(features_to_remove):
        print(f"     - {feat}")
    
    return features_to_remove

def main():
    parser = argparse.ArgumentParser(
        description='–ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Ñ–∏—á–µ–π –∏ —É–¥–∞–ª–µ–Ω–∏–µ –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python analyze_feature_correlation.py                    # –ê–Ω–∞–ª–∏–∑ —Å –ø–æ—Ä–æ–≥–æ–º 0.95
  python analyze_feature_correlation.py --threshold 0.90   # –ü–æ—Ä–æ–≥ 0.90
  python analyze_feature_correlation.py --remove          # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª–∏—Ç—å
  python analyze_feature_correlation.py --plot            # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫
        """
    )
    
    parser.add_argument(
        '--input',
        type=str,
        default='workspace/prepared/features/gold_train.csv',
        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: workspace/prepared/features/gold_train.csv)'
    )
    
    parser.add_argument(
        '--threshold',
        type=float,
        default=0.95,
        help='–ü–æ—Ä–æ–≥ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.95)'
    )
    
    parser.add_argument(
        '--remove',
        action='store_true',
        help='–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª–∏—Ç—å –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏—á–∏'
    )
    
    parser.add_argument(
        '--plot',
        action='store_true',
        help='–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã'
    )
    
    parser.add_argument(
        '--output',
        type=str,
        default='workspace/prepared/features/gold_train_no_corr.csv',
        help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∏—á–µ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: workspace/prepared/features/gold_train_no_corr.csv)'
    )
    
    parser.add_argument(
        '--save-tables',
        action='store_true',
        default=True,
        help='–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ç–∞–±–ª–∏—Ü—ã CSV (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –≤–∫–ª—é—á–µ–Ω–æ)'
    )
    
    parser.add_argument(
        '--output-dir',
        type=str,
        default=None,
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: —Ç–∞ –∂–µ, —á—Ç–æ –∏ –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª)'
    )
    
    parser.add_argument(
        '--features-to-remove',
        type=str,
        default=None,
        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–æ —Å–ø–∏—Å–∫–æ–º —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è (CSV —Å –∫–æ–ª–æ–Ω–∫–æ–π Feature)'
    )
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("–ê–ù–ê–õ–ò–ó –ö–û–†–†–ï–õ–Ø–¶–ò–ò –§–ò–ß–ï–ô")
    print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print(f"\n1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {args.input}...")
    try:
        df = pd.read_csv(args.input, index_col=0, parse_dates=True)
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
    except FileNotFoundError:
        print(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª {args.input} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python prepare_gold_data.py")
        return
    
    # –í—ã–±–æ—Ä —Ñ–∏—á–µ–π (–∏—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ)
    print("\n2. –í—ã–±–æ—Ä —Ñ–∏—á–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")
    exclude_patterns = ['future_return', 'signal_class', 'signal_class_name', 'max_future_return']
    feature_columns = [
        col for col in df.columns 
        if not any(pattern in col for pattern in exclude_patterns)
        and pd.api.types.is_numeric_dtype(df[col])
    ]
    
    print(f"   –ù–∞–π–¥–µ–Ω–æ {len(feature_columns)} —Ñ–∏—á–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
    print("\n3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    nan_counts = df[feature_columns].isna().sum()
    cols_with_nan = nan_counts[nan_counts > 0]
    if len(cols_with_nan) > 0:
        print(f"   ‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(cols_with_nan)} —Ñ–∏—á–µ–π —Å NaN –∑–Ω–∞—á–µ–Ω–∏—è–º–∏")
        print(f"   –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –º–µ–¥–∏–∞–Ω–æ–π...")
        df[feature_columns] = df[feature_columns].fillna(df[feature_columns].median())
    else:
        print("   ‚úì NaN –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if args.output_dir:
        output_dir = Path(args.output_dir)
    else:
        output_dir = Path(args.input).parent
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    print(f"\n4. –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (–ø–æ—Ä–æ–≥: {args.threshold})...")
    high_corr_pairs = find_highly_correlated_pairs(df, feature_columns, args.threshold)
    
    if len(high_corr_pairs) == 0:
        print(f"   ‚úì –í—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä (>{args.threshold}) –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    else:
        print(f"   –ù–∞–π–¥–µ–Ω–æ {len(high_corr_pairs)} –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä:")
        print("\n   –¢–æ–ø-20 –ø–∞—Ä —Å –Ω–∞–∏–≤—ã—Å—à–µ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π:")
        for i, (feat1, feat2, corr) in enumerate(high_corr_pairs[:20], 1):
            print(f"   {i:2d}. {feat1[:40]:40s} <-> {feat2[:40]:40s} : {corr:6.3f}")
        
        if len(high_corr_pairs) > 20:
            print(f"   ... –∏ –µ—â–µ {len(high_corr_pairs) - 20} –ø–∞—Ä")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä –≤ —Ç–∞–±–ª–∏—Ü—É
        if args.save_tables:
            pairs_df = pd.DataFrame(high_corr_pairs, columns=['Feature_1', 'Feature_2', 'Correlation'])
            pairs_df['Abs_Correlation'] = pairs_df['Correlation'].abs()
            pairs_df = pairs_df.sort_values('Abs_Correlation', ascending=False)
            pairs_path = output_dir / f'highly_correlated_pairs_threshold_{args.threshold:.2f}.csv'
            pairs_df.to_csv(pairs_path, index=False)
            print(f"\n   ‚úì –¢–∞–±–ª–∏—Ü–∞ –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {pairs_path}")
    
    # –í—ã–±–æ—Ä —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    features_to_remove = set()
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Ñ–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è, –∑–∞–≥—Ä—É–∂–∞–µ–º –µ–≥–æ
    if args.features_to_remove and Path(args.features_to_remove).exists():
        print("\n5. –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞...")
        remove_list_df = pd.read_csv(args.features_to_remove)
        if 'Feature' in remove_list_df.columns:
            features_to_remove = set(remove_list_df['Feature'].tolist())
            print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(features_to_remove)} —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")
        else:
            print("   ‚ö†Ô∏è  –í —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'Feature', –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏")
            args.features_to_remove = None
    
    if args.remove and len(high_corr_pairs) > 0 and not features_to_remove:
        print("\n5. –í—ã–±–æ—Ä —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è...")
        print(f"   –ó–∞—â–∏—â–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ (–Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —É–¥–∞–ª—è—é—Ç—Å—è): {', '.join(PROTECTED_FEATURES)}")
        features_to_remove = select_features_to_remove(high_corr_pairs, feature_columns)
        print(f"   –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ {len(features_to_remove)} —Ñ–∏—á–µ–π:")
        for feat in sorted(features_to_remove):
            print(f"     - {feat}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤ —Ç–∞–±–ª–∏—Ü—É
        if args.save_tables:
            remove_df = pd.DataFrame({
                'Feature': sorted(features_to_remove),
                'Reason': 'High correlation with other features'
            })
            remove_path = output_dir / f'features_to_remove_threshold_{args.threshold:.2f}.csv'
            remove_df.to_csv(remove_path, index=False)
            print(f"   ‚úì –¢–∞–±–ª–∏—Ü–∞ —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {remove_path}")
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∏—á–µ–π
        print(f"\n6. –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∏—á–µ–π –∏–∑ –¥–∞–Ω–Ω—ã—Ö...")
        df_cleaned = df.drop(columns=list(features_to_remove))
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        print(f"\n7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ {args.output}...")
        df_cleaned.to_csv(args.output)
        print(f"   ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(df_cleaned)} —Å—Ç—Ä–æ–∫, {len(df_cleaned.columns)} –∫–æ–ª–æ–Ω–æ–∫")
        print(f"   –£–¥–∞–ª–µ–Ω–æ {len(features_to_remove)} —Ñ–∏—á–µ–π")
        print(f"   –û—Å—Ç–∞–ª–æ—Å—å {len(df_cleaned.columns) - len([c for c in df_cleaned.columns if any(p in c for p in exclude_patterns)])} —Ñ–∏—á–µ–π")
    elif len(high_corr_pairs) > 0:
        # –ï—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è --remove, –Ω–æ –µ—Å—Ç—å –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä—ã, –≤—Å–µ —Ä–∞–≤–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏–º —Å–ø–∏—Å–æ–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
        if args.save_tables:
            print("\n5. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è...")
            print(f"   –ó–∞—â–∏—â–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ (–Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —É–¥–∞–ª—è—é—Ç—Å—è): {', '.join(PROTECTED_FEATURES)}")
            potential_remove = select_features_to_remove(high_corr_pairs, feature_columns)
            if len(potential_remove) > 0:
                remove_df = pd.DataFrame({
                    'Feature': sorted(potential_remove),
                    'Reason': 'High correlation with other features',
                    'Note': 'Use --remove to actually remove these features'
                })
                remove_path = output_dir / f'potential_features_to_remove_threshold_{args.threshold:.2f}.csv'
                remove_df.to_csv(remove_path, index=False)
                print(f"   ‚úì –¢–∞–±–ª–∏—Ü–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ñ–∏—á–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {remove_path}")
    
    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
    if args.plot:
        step_num = "8" if args.remove and len(high_corr_pairs) > 0 else "6"
        print(f"\n{step_num}. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã...")
        plot_path = output_dir / f'{Path(args.input).stem}_correlation_matrix.png'
        plot_correlation_matrix(df, feature_columns[:50], save_path=str(plot_path))
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü—É
    if args.save_tables:
        stats_data = {
            'Metric': [
                'Total Features',
                f'Highly Correlated Pairs (>{args.threshold})',
                'Features to Remove',
                'Features Remaining'
            ],
            'Value': [
                len(feature_columns),
                len(high_corr_pairs),
                len(features_to_remove) if features_to_remove else 0,
                len(feature_columns) - len(features_to_remove) if features_to_remove else len(feature_columns)
            ]
        }
        stats_df = pd.DataFrame(stats_data)
        stats_path = output_dir / f'correlation_analysis_stats_threshold_{args.threshold:.2f}.csv'
        stats_df.to_csv(stats_path, index=False)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 80)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 80)
    print(f"–í—Å–µ–≥–æ —Ñ–∏—á–µ–π: {len(feature_columns)}")
    print(f"–í—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä (>{args.threshold}): {len(high_corr_pairs)}")
    if features_to_remove:
        print(f"–£–¥–∞–ª–µ–Ω–æ —Ñ–∏—á–µ–π: {len(features_to_remove)}")
        print(f"–û—Å—Ç–∞–ª–æ—Å—å —Ñ–∏—á–µ–π: {len(feature_columns) - len(features_to_remove)}")
    print("=" * 80)
    
    if args.save_tables:
        print(f"\nüìä –í—Å–µ —Ç–∞–±–ª–∏—Ü—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if len(high_corr_pairs) > 0:
        print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        print("   1. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —É–¥–∞–ª–µ–Ω–∏—è –≤—ã—Å–æ–∫–æ–∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∏—á–µ–π")
        print("   2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å —Ñ–ª–∞–≥–æ–º --remove –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è")
        print("   3. –ë–∞–∑–æ–≤—ã–µ OHLC —Ü–µ–Ω—ã (open, high, low, close) –∑–∞—â–∏—â–µ–Ω—ã –∏ –Ω–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã")
        print("   4. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ—Ç–¥–∞–µ—Ç—Å—è –ø—Ä–æ—Å—Ç—ã–º/–∫–æ—Ä–æ—Ç–∫–∏–º –∏–º–µ–Ω–∞–º (sma_5 > close_rolling_mean_5)")
        print("   5. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ")
        print("   6. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --plot –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π")

if __name__ == '__main__':
    main()

