# Walk-Forward Validation: Теория и Практика

## Содержание

1. [Введение](#введение)
2. [Теоретическая основа](#теоретическая-основа)
3. [Концепция "подхода" vs "модели"](#концепция-подхода-vs-модели)
4. [Место в структуре проекта](#место-в-структуре-проекта)
5. [Как это работает](#как-это-работает)
6. [Таргеты в Walk-Forward Validation](#таргеты-в-walk-forward-validation)
7. [Проблема недостаточного обучения](#проблема-недостаточного-обучения)
8. [Интерпретация результатов](#интерпретация-результатов)
9. [Практическое руководство](#практическое-руководство)
10. [Часто задаваемые вопросы](#часто-задаваемые-вопросы)

---

## Введение

**Walk-Forward Validation** (валидация с движущимся окном) — это метод оценки качества моделей машинного обучения для временных рядов, который симулирует реальную торговлю, где модель обучается на исторических данных и тестируется на будущих данных.

### Зачем это нужно?

В реальной торговле:
- Модель обучается на прошлом
- Тестируется на будущем
- Рыночные условия меняются со временем
- Нужна уверенность, что модель будет работать стабильно

Walk-Forward Validation позволяет проверить это **до** запуска в продакшен.

---

## Теоретическая основа

### Проблема обычного train/val/test разделения

**Обычное обучение:**
```
┌─────────────────────────────────────────┐
│ ВСЕ ДАННЫЕ                              │
│ ┌──────────┐ ┌──────┐ ┌──────┐         │
│ │  TRAIN   │ │ VAL  │ │ TEST │         │
│ │  70%     │ │ 15%  │ │ 15%  │         │
│ └──────────┘ └──────┘ └──────┘         │
│                                          │
│ ОДНО РАЗДЕЛЕНИЕ (статическое)          │
│ ОДНО ОБУЧЕНИЕ                           │
└─────────────────────────────────────────┘
```

**Проблемы:**
- ❌ Не учитывает временную структуру данных
- ❌ Может быть переобучение на конкретный период
- ❌ Не показывает, как модель будет работать в будущем
- ❌ Одна оценка качества (может быть случайной)

### Решение: Walk-Forward Validation

**Walk-Forward Validation:**
```
┌─────────────────────────────────────────┐
│ ВСЕ ДАННЫЕ (объединенные)               │
│                                          │
│ ┌──────────┐ ┌──────┐ ┌──────┐         │
│ │  TRAIN   │ │ VAL  │ │ TEST │ Fold 1  │
│ └──────────┘ └──────┘ └──────┘         │
│     ↓         ↓         ↓                │
│ ┌──────────┐ ┌──────┐ ┌──────┐         │
│ │  TRAIN   │ │ VAL  │ │ TEST │ Fold 2  │
│ └──────────┘ └──────┘ └──────┘         │
│     ↓         ↓         ↓                │
│ ┌──────────┐ ┌──────┐ ┌──────┐         │
│ │  TRAIN   │ │ VAL  │ │ TEST │ Fold 3  │
│ └──────────┘ └──────┘ └──────┘         │
│                                          │
│ МНОЖЕСТВЕННЫЕ ОКНА (движущиеся)         │
│ N ОБУЧЕНИЙ (по количеству fold'ов)     │
└─────────────────────────────────────────┘
```

**Преимущества:**
- ✅ Учитывает временную структуру
- ✅ Симулирует реальную торговлю
- ✅ Показывает стабильность модели во времени
- ✅ Множественные оценки качества (более надежно)

---

## Концепция "подхода" vs "модели"

### Что такое "подход"?

**Подход (Method/Approach)** — это совокупность всех компонентов системы обучения:

```python
Подход = {
    'архитектура': 'Transformer Encoder',
    'параметры_архитектуры': {
        'd_model': 256,
        'n_layers': 4,
        'n_heads': 8,
        'dropout': 0.1
    },
    'набор_фичей': [
        'RSI', 'MACD', 'support_level', 'resistance_level',
        'tick_features', 'volatility_features', ...
    ],
    'процесс_обучения': {
        'learning_rate': 1e-4,
        'batch_size': 32,
        'num_epochs': 100,
        'scheduler': 'cosine',
        'weight_decay': 1e-5
    },
    'обработка_данных': {
        'sequence_length': 60,
        'scaling': 'StandardScaler',
        'class_weights': 'balanced'
    }
}
```

### Что такое "конкретная модель"?

**Конкретная модель** — это одна обученная модель с конкретными весами:
- Обучена на конкретном наборе данных
- Имеет конкретные веса для каждого нейрона
- Работает хорошо на данных, на которых обучалась

### Что проверяет Walk-Forward Validation?

**Вопрос:** Работает ли **подход** стабильно на разных временных периодах?

**Не проверяет:** Работает ли конкретная модель (с конкретными весами)?

**Проверяет:** Работает ли метод обучения (архитектура + фичи + процесс) стабильно?

### Пример проверки подхода:

```
Подход: Transformer Encoder + RSI/MACD + тики + learning_rate=1e-4

Fold 1 (Период A):
  → Создаем модель с этим подходом
  → Обучаем на данных Периода A
  → Тестируем на будущем
  → Результат: accuracy = 0.75

Fold 2 (Период B):
  → Создаем модель с ЭТИМ ЖЕ подходом (те же параметры!)
  → Обучаем на данных Периода B
  → Тестируем на будущем
  → Результат: accuracy = 0.73

Fold 3 (Период C):
  → Создаем модель с ЭТИМ ЖЕ подходом
  → Обучаем на данных Периода C
  → Тестируем на будущем
  → Результат: accuracy = 0.76

Вывод: Подход стабилен! (0.75 ± 0.015)
       - Работает хорошо на разных периодах
       - Не зависит от конкретных данных
       - Можно использовать в продакшене
```

---

## Место в структуре проекта

### Структура full_pipeline.py:

```
┌─────────────────────────────────────────────────────────────┐
│ ЭТАП 1: Подготовка данных                                  │
│   (prepare_gold_data.py)                                    │
└─────────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────────┐
│ ЭТАП 2: Обучение моделей                                    │
│                                                              │
│   ┌──────────────────────────────────────┐                  │
│   │ ВАРИАНТ A: Обычное обучение         │                  │
│   │   (train_all_models.py)              │                  │
│   │   - Одно обучение на train/val/test  │                  │
│   │   - Быстро, для экспериментов        │                  │
│   └──────────────────────────────────────┘                  │
│                    ИЛИ                                       │
│   ┌──────────────────────────────────────┐                  │
│   │ ВАРИАНТ B: Walk-Forward Validation   │                  │
│   │   (validation/walk_forward.py)        │                  │
│   │   - Множественные fold'ы              │                  │
│   │   - Окно движется по времени         │                  │
│   │   - Более реалистичная оценка         │                  │
│   │   - Медленнее (обучение N раз)        │                  │
│   └──────────────────────────────────────┘                  │
└─────────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────────┐
│ ЭТАП 3: Бэктестинг                                          │
│   (backtest_strategy.py)                                     │
└─────────────────────────────────────────────────────────────┘
```

### Активация Walk-Forward Validation:

```bash
# Обычное обучение (по умолчанию)
python full_pipeline.py --months 6 --encoder-only

# Walk-Forward Validation (с флагом)
python full_pipeline.py --months 6 --encoder-only --use-walk-forward
```

### Когда использовать?

**Обычное обучение:**
- ✅ Быстрое тестирование и эксперименты
- ✅ Ограниченные ресурсы (время/GPU)
- ✅ Первичная оценка модели
- ✅ Мало данных (< 60 дней)

**Walk-Forward Validation:**
- ✅ Финальная валидация перед продакшеном
- ✅ Нужна более реалистичная оценка производительности
- ✅ Достаточно данных (минимум 60-90 дней для 3-5 fold'ов)
- ✅ Достаточно времени (обучение выполняется N раз)

---

## Как это работает

### Алгоритм Walk-Forward Validation:

```
1. Объединить все данные (train + val + test)
2. Создать множественные окна (fold'ы):
   
   Fold 1:
     Train: [0..train_days]
     Val:   [train_days..train_days+val_days]
     Test:  [train_days+val_days..train_days+val_days+test_days]
   
   Fold 2 (сдвиг на step_days):
     Train: [step_days..step_days+train_days]
     Val:   [step_days+train_days..step_days+train_days+val_days]
     Test:  [step_days+train_days+val_days..step_days+train_days+val_days+test_days]
   
   Fold 3 (еще сдвиг):
     ...

3. Для каждого fold'а:
   a. Создать НОВУЮ модель (не использовать предыдущую!)
   b. Обучить на train данных этого fold'а
   c. Валидировать на val данных этого fold'а
   d. Тестировать на test данных этого fold'а
   e. Сохранить метрики

4. Агрегировать результаты:
   - Среднее значение метрик
   - Стандартное отклонение
   - Минимум и максимум
   - Медиана
```

### Параметры окон:

**Автоматический расчет** (рекомендуется):
```python
# Система автоматически вычисляет оптимальные параметры:
min_train = 30 дней    # Минимум для обучения
min_val = 7 дней       # Минимум для валидации
min_test = 7 дней       # Минимум для тестирования
max_train = 120 дней   # Максимум (чтобы было достаточно fold'ов)
target_folds = 3-10    # Целевое количество fold'ов
```

**Ручная настройка:**
```bash
python full_pipeline.py \
    --use-walk-forward \
    --walk-forward-train-days 60 \
    --walk-forward-val-days 15 \
    --walk-forward-test-days 15 \
    --walk-forward-step-days 10
```

---

## Таргеты в Walk-Forward Validation

### Использование таргетов

**Важно:** Таргеты используются одинаково в обоих процессах обучения!

**Таргет:** `signal_class` (0-4)
- `0` = uncertainty (неопределенность)
- `1` = breakout_up (пробой вверх)
- `2` = breakout_down (пробой вниз)
- `3` = bounce_up (отскок вверх)
- `4` = bounce_down (отскок вниз)

### В обычном обучении:

```python
# Загружаем готовые разделенные данные
train_df = pd.read_csv('gold_train.csv')  # С таргетами
val_df = pd.read_csv('gold_val.csv')      # С таргетами
test_df = pd.read_csv('gold_test.csv')    # С таргетами

# Одно обучение
train_loader, val_loader, test_loader = create_dataloaders(
    train_df, val_df, test_df,
    target_column='signal_class'  # ← Тот же таргет
)
```

### В Walk-Forward Validation:

```python
# Объединяем все данные
all_data = pd.concat([train_df, val_df, test_df])

# Для каждого fold'а:
for fold in folds:
    train_df_fold = all_data[fold['train_indices']]  # С таргетами
    val_df_fold = all_data[fold['val_indices']]      # С таргетами
    test_df_fold = all_data[fold['test_indices']]    # С таргетами
    
    # Обучаем модель (тот же таргет!)
    train_loader, val_loader, _ = create_dataloaders(
        train_df_fold, val_df_fold, test_df_fold,
        target_column='signal_class'  # ← Тот же таргет
    )
```

### Ключевой момент:

- **Таргеты одинаковые** в обоих процессах
- **Различие** только в способе разделения данных
- Walk-Forward Validation **не использует** уже обученную модель
- Каждый fold создает и обучает **новую модель** с нуля

---

## Проблема недостаточного обучения

### Проблема

На меньшей выборке модель может не успеть достаточно обучиться:

```
Обычное обучение:
  Данные: 180 дней (6 месяцев)
  Эпох: 100
  → Модель успевает обучиться
  
Walk-Forward Fold:
  Данные: 30 дней (минимум)
  Эпох: 100 (те же)
  → Модель может НЕ успеть обучиться!
```

### Как это учитывается

#### 1. Минимальные требования

```python
min_train = 30 дней  # Гарантирует минимальный объем данных
```

#### 2. Early Stopping

```python
trainer.train(
    num_epochs=100,
    early_stopping_patience=10,  # Останавливает, если нет улучшения
    ...
)
```

#### 3. Анализ сходимости

Важно проверять не только финальные метрики, но и процесс обучения:
- На какой эпохе остановилось обучение?
- Снижался ли loss?
- Сработал ли early stopping?

### Интерпретация результатов

#### Сценарий A: Модель успевает обучиться ✅

```
Fold 1: accuracy = 0.75 (early stopping на эпохе 25)
Fold 2: accuracy = 0.73 (early stopping на эпохе 28)
Fold 3: accuracy = 0.76 (early stopping на эпохе 22)

Среднее: 0.75 ± 0.015

Вывод: ✅ Подход хороший
       - Модель успевает обучиться
       - Результаты стабильны
       - Можно использовать в продакшене
```

#### Сценарий B: Модель не успевает обучиться ❌

```
Fold 1: accuracy = 0.55 (обучение до 100 эпох, loss все еще снижается)
Fold 2: accuracy = 0.52 (обучение до 100 эпох, loss все еще снижается)
Fold 3: accuracy = 0.58 (обучение до 100 эпох, loss все еще снижается)

Среднее: 0.55 ± 0.03

Вывод: ❌ Проблема!
       - Модель НЕ успевает обучиться на меньшей выборке
       - Нужно увеличить размер train окна
       - Или упростить модель
       - Или увеличить количество эпох
```

### Решения проблемы

#### Решение 1: Увеличить размер train окна

```bash
python full_pipeline.py \
    --use-walk-forward \
    --walk-forward-train-days 60  # Вместо 30
```

#### Решение 2: Увеличить количество эпох

```bash
python full_pipeline.py \
    --use-walk-forward \
    --epochs 200  # Вместо 100
```

#### Решение 3: Упростить модель

Уменьшить количество слоев или размерность модели в конфигурации.

#### Решение 4: Проверить сходимость

Анализировать логи обучения для каждого fold'а:
- Сработал ли early stopping?
- На какой эпохе остановилось обучение?
- Снижался ли loss стабильно?

---

## Интерпретация результатов

### Агрегированные метрики

После Walk-Forward Validation вы получаете:

```python
{
    'accuracy_mean': 0.745,
    'accuracy_std': 0.012,      # ← КЛЮЧЕВОЙ ПОКАЗАТЕЛЬ!
    'accuracy_min': 0.730,
    'accuracy_max': 0.760,
    'accuracy_median': 0.745,
    
    'f1_mean': 0.696,
    'f1_std': 0.015,
    ...
}
```

### Ключевые показатели

#### 1. Стандартное отклонение (std)

**Низкое std (< 0.05):**
- ✅ Модель стабильна
- ✅ Не переобучена
- ✅ Результаты предсказуемы

**Высокое std (> 0.10):**
- ❌ Модель нестабильна
- ❌ Возможна переобученность
- ❌ Результаты непредсказуемы

#### 2. Разброс (max - min)

**Маленький разброс (< 0.10):**
- ✅ Модель работает стабильно на всех периодах

**Большой разброс (> 0.20):**
- ❌ Модель работает хорошо на одних периодах и плохо на других
- ❌ Возможна переобученность на конкретные паттерны

#### 3. Абсолютная точность

**Высокая точность + стабильность:**
- ✅ Подход хороший, можно использовать

**Низкая точность + стабильность:**
- ⚠️ Подход стабилен, но неэффективен
- ⚠️ Нужно улучшить (фичи, архитектуру)

**Низкая точность + нестабильность:**
- ❌ Подход плохой, нужна доработка

### Типичные сценарии

#### Сценарий 1: Идеальный результат ✅

```
Fold 1: accuracy = 0.75, f1 = 0.70
Fold 2: accuracy = 0.73, f1 = 0.68
Fold 3: accuracy = 0.76, f1 = 0.71
Fold 4: accuracy = 0.74, f1 = 0.69
Fold 5: accuracy = 0.75, f1 = 0.70

Среднее: accuracy = 0.746 ± 0.012, f1 = 0.696 ± 0.011

Анализ:
  ✅ Низкое std (0.012) → стабильность
  ✅ Высокая точность (0.746) → эффективность
  ✅ Маленький разброс (0.73-0.76) → предсказуемость

Вывод: Подход отличный, готов к продакшену!
```

#### Сценарий 2: Переобученная модель ❌

```
Fold 1: accuracy = 0.85, f1 = 0.80  ← Отлично!
Fold 2: accuracy = 0.55, f1 = 0.45  ← Провал!
Fold 3: accuracy = 0.88, f1 = 0.82  ← Отлично!
Fold 4: accuracy = 0.52, f1 = 0.48  ← Провал!

Среднее: accuracy = 0.70 ± 0.18, f1 = 0.64 ± 0.18

Анализ:
  ❌ Высокое std (0.18) → нестабильность
  ⚠️ Средняя точность (0.70) → неэффективность
  ❌ Большой разброс (0.52-0.88) → непредсказуемость

Вывод: Модель переобучена на конкретные периоды!
       Нужно:
       1. Улучшить набор фичей
       2. Изменить архитектуру
       3. Настроить гиперпараметры
```

#### Сценарий 3: Недостаточное обучение ⚠️

```
Fold 1: accuracy = 0.55, f1 = 0.50
Fold 2: accuracy = 0.54, f1 = 0.49
Fold 3: accuracy = 0.56, f1 = 0.51
Fold 4: accuracy = 0.55, f1 = 0.50

Среднее: accuracy = 0.55 ± 0.008, f1 = 0.50 ± 0.008

Анализ:
  ✅ Низкое std (0.008) → стабильность
  ❌ Низкая точность (0.55) → неэффективность
  ⚠️ Модель не успевает обучиться

Вывод: Подход стабилен, но модель не успевает обучиться!
       Нужно:
       1. Увеличить размер train окна
       2. Упростить модель
       3. Увеличить количество эпох
```

---

## Практическое руководство

### Базовое использование

```bash
# С автоматическим вычислением параметров (рекомендуется)
python full_pipeline.py \
    --skip-prepare \
    --use-walk-forward \
    --encoder-only \
    --epochs 100 \
    --batch-size 32
```

### С указанными параметрами

```bash
python full_pipeline.py \
    --skip-prepare \
    --use-walk-forward \
    --encoder-only \
    --walk-forward-train-days 60 \
    --walk-forward-val-days 15 \
    --walk-forward-test-days 15 \
    --walk-forward-step-days 10 \
    --epochs 100
```

### Полный цикл с Walk-Forward Validation

```bash
# 1. Подготовка данных (нужно больше данных)
python prepare_gold_data.py --months 12

# 2. Walk-Forward Validation
python full_pipeline.py \
    --skip-prepare \
    --use-walk-forward \
    --encoder-only \
    --epochs 100 \
    --batch-size 32

# 3. Анализ результатов
# Открыть workspace/results/walk_forward/walk_forward_results.csv
```

### Результаты

После выполнения Walk-Forward Validation создаются:

1. **Детальные результаты:** `workspace/results/walk_forward/walk_forward_results.csv`
   - Метрики для каждого fold'а
   - Даты начала и конца каждого окна
   - Количество образцов в каждом окне

2. **Агрегированные метрики:** Выводятся в консоль
   - Среднее значение (mean)
   - Стандартное отклонение (std)
   - Минимум и максимум
   - Медиана

3. **Последняя модель:** `workspace/models/checkpoints/encoder_model.pth`
   - Модель из последнего fold'а
   - Можно использовать для бэктестинга
   - Рекомендуется выбрать лучшую по метрикам

### Анализ результатов

#### Шаг 1: Открыть результаты

```python
import pandas as pd

results_df = pd.read_csv('workspace/results/walk_forward/walk_forward_results.csv')
print(results_df[['fold_id', 'accuracy', 'f1', 'precision', 'recall']])
```

#### Шаг 2: Вычислить статистику

```python
# Статистика по accuracy
print(f"Среднее accuracy: {results_df['accuracy'].mean():.4f}")
print(f"Std accuracy: {results_df['accuracy'].std():.4f}")
print(f"Min accuracy: {results_df['accuracy'].min():.4f}")
print(f"Max accuracy: {results_df['accuracy'].max():.4f}")
print(f"Разброс: {results_df['accuracy'].max() - results_df['accuracy'].min():.4f}")
```

#### Шаг 3: Интерпретация

**Хорошие результаты:**
- Низкое std (< 0.05)
- Высокая точность (> 0.70)
- Маленький разброс (< 0.10)

**Плохие результаты:**
- Высокое std (> 0.10)
- Низкая точность (< 0.60)
- Большой разброс (> 0.20)

---

## Часто задаваемые вопросы

### Q1: Нужна ли уже обученная модель для Walk-Forward Validation?

**A:** Нет! Walk-Forward Validation создает и обучает новую модель для каждого fold'а с нуля. Он не использует уже обученную модель из предыдущего этапа.

### Q2: Используются ли одинаковые таргеты в обоих процессах?

**A:** Да! И в обычном обучении, и в Walk-Forward Validation используется один и тот же таргет: `signal_class` (0-4). Различие только в способе разделения данных.

### Q3: Что если модель не успевает обучиться на меньшей выборке?

**A:** Это важная проблема! Если модель не успевает обучиться:
- Увеличьте размер train окна (`--walk-forward-train-days`)
- Упростите модель (меньше слоев)
- Увеличьте количество эпох (`--epochs`)
- Проверьте логи обучения (сходимость, early stopping)

### Q4: Как выбрать лучшую модель из Walk-Forward Validation?

**A:** В текущей реализации сохраняется только последняя модель. Рекомендуется:
1. Открыть `walk_forward_results.csv`
2. Найти fold с лучшими метриками
3. Обучить модель заново на данных этого fold'а
4. Или использовать ансамбль всех моделей (требует доработки)

### Q5: Сколько времени занимает Walk-Forward Validation?

**A:** Если обычное обучение занимает T времени, то Walk-Forward Validation займет примерно:
- **Время = T × N**, где N - количество fold'ов
- Например: если обучение занимает 1 час и создается 5 fold'ов, то Walk-Forward займет ~5 часов

### Q6: Можно ли использовать Walk-Forward Validation для выбора гиперпараметров?

**A:** Технически да, но это будет очень медленно (обучение N раз для каждого набора гиперпараметров). Лучше сначала выбрать гиперпараметры через обычное обучение, а затем проверить их стабильность через Walk-Forward Validation.

### Q7: Что делать, если результаты нестабильны?

**A:** Если результаты нестабильны (высокое std):
1. Проверьте набор фичей (возможно, переобучение на конкретные паттерны)
2. Упростите модель (меньше параметров)
3. Увеличьте регуляризацию (dropout, weight_decay)
4. Проверьте распределение классов (возможно, несбалансированность)
5. Увеличьте размер train окна

### Q8: Можно ли использовать Walk-Forward Validation для финальной модели?

**A:** Walk-Forward Validation используется для **оценки** подхода, а не для создания финальной модели. После валидации рекомендуется:
1. Выбрать лучший подход (на основе стабильности)
2. Обучить финальную модель на всех доступных данных
3. Использовать эту модель в продакшене

---

## Рекомендации по использованию

### Минимальные требования

- **Данные:** Минимум 60-90 дней для создания 3-5 fold'ов
- **Время:** В N раз больше, чем обычное обучение (N = количество fold'ов)
- **Ресурсы:** Достаточно GPU/CPU для N обучений

### Оптимальные параметры

- **Train окно:** 60-90 дней (достаточно для обучения, но не слишком много)
- **Val окно:** 15-20 дней
- **Test окно:** 15-20 дней
- **Step:** 10-15 дней (для создания 5-10 fold'ов)

### Когда использовать

**Используйте Walk-Forward Validation:**
- ✅ Перед финальным запуском в продакшен
- ✅ Когда нужно проверить стабильность подхода
- ✅ Когда есть достаточно данных и времени
- ✅ Когда нужно убедиться, что модель не переобучена

**Не используйте Walk-Forward Validation:**
- ❌ Для быстрого тестирования и экспериментов
- ❌ Когда мало данных (< 60 дней)
- ❌ Когда ограничены ресурсы (время/GPU)
- ❌ Для первичной оценки модели

---

## Дополнительные ресурсы

- [17_FULL_PIPELINE_GUIDE.md](17_FULL_PIPELINE_GUIDE.md) - Руководство по full_pipeline.py
- [04_TRAINING_GUIDE.md](04_TRAINING_GUIDE.md) - Общее руководство по обучению
- [validation/walk_forward.py](../validation/walk_forward.py) - Исходный код
- [examples/walk_forward_example.py](../examples/walk_forward_example.py) - Пример использования

---

**Последнее обновление:** Документация создана на основе обсуждения концепции Walk-Forward Validation и его реализации в проекте.

