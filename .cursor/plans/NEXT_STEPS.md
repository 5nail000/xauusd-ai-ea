# Следующие шаги перед финальным обучением

## ⚠️ ВАЖНО: Проверьте эти пункты перед обучением на полном датасете

### 1. Проверка распределения классов

**Цель:** Убедиться, что классы сбалансированы после изменения порогов.

**Действие:**
```python
import pandas as pd

train_df = pd.read_csv('workspace/prepared/features/gold_train.csv', index_col=0)
print(train_df['signal_class'].value_counts(normalize=True))
```

**Ожидаемое распределение:**
- Класс 0 (Неопределенность): ~60-70%
- Класс 1 (Пробой вверх): ~10-15%
- Класс 2 (Пробой вниз): ~10-15%
- Класс 3 (Отскок вверх): ~3-7%
- Класс 4 (Отскок вниз): ~3-7%

**Если распределение неправильное:**
- Увеличьте пороги `breakout_threshold` и `bounce_threshold` в `data/target_generator.py`
- Проверьте логику генерации таргетов
- Рассмотрите использование class weights в loss функции

### 2. Проверка на Data Leakage

**Цель:** Убедиться, что фичи не содержат информации о будущем.

**Действие:**
```python
# Проверьте корреляцию фичей с таргетом
correlations = train_df.corr()['signal_class'].abs().sort_values(ascending=False)
print(correlations.head(20))

# Подозрительные фичи (корреляция > 0.8):
suspicious = correlations[correlations > 0.8]
if len(suspicious) > 1:  # 1 - это сам таргет
    print("⚠️ Обнаружены подозрительно высокие корреляции!")
    print(suspicious)
```

**Что искать:**
- Фичи с корреляцией > 0.8 с таргетом (кроме самого таргета)
- Фичи, которые используют будущие данные (например, `future_return_*`)
- Фичи, которые вычисляются с использованием данных после текущего момента

### 3. Валидация генерации таргетов

**Цель:** Визуально проверить, что таргеты генерируются правильно.

**Действие:**
```python
import matplotlib.pyplot as plt
import pandas as pd

# Загрузите данные
df = pd.read_csv('workspace/prepared/features/gold_train.csv', index_col=0, parse_dates=True)

# Выберите несколько примеров каждого класса
for class_id in [1, 2, 3, 4]:
    examples = df[df['signal_class'] == class_id].head(5)
    for idx, row in examples.iterrows():
        # Визуализируйте цену вокруг этого момента
        start_idx = df.index.get_loc(idx) - 30
        end_idx = df.index.get_loc(idx) + 60
        subset = df.iloc[start_idx:end_idx]
        
        plt.figure(figsize=(12, 6))
        plt.plot(subset.index, subset['close'], label='Price')
        plt.axvline(idx, color='red', linestyle='--', label=f'Signal: Class {class_id}')
        plt.title(f'Class {class_id} example at {idx}')
        plt.legend()
        plt.show()
```

**Что проверить:**
- Пробои (классы 1, 2) действительно происходят при сильном движении
- Отскоки (классы 3, 4) действительно происходят после разворота
- Сигналы не появляются в случайных местах

### 4. Тестирование на малой выборке

**Цель:** Убедиться, что весь pipeline работает корректно перед полным обучением.

**Действие:**
1. Подготовьте данные на 1-2 месяца:
   ```bash
   python prepare_gold_data.py --months 2
   ```

2. Обучите модель на малой выборке:
   ```bash
   python train_model.py --use-wandb
   ```

3. Проверьте метрики:
   - Accuracy должна быть > 50% (лучше случайного)
   - Loss должна уменьшаться
   - Нет ошибок в процессе обучения

**Если что-то не работает:**
- Исправьте ошибки
- Проверьте логи
- Убедитесь, что все зависимости установлены

### 5. Проверка метрик на валидационной выборке

**Цель:** Убедиться, что модель не переобучается.

**Действие:**
После обучения проверьте:
- Confusion matrix (должна быть в `workspace/models/metrics/`)
- Classification report
- Разницу между train и val accuracy (не должна быть > 15%)

**Что искать:**
- Precision и Recall по каждому классу
- Классы с низкой точностью (возможно, нужно больше данных)
- Признаки переобучения (большой gap между train и val)

### 6. Анализ Confusion Matrix

**Цель:** Выявить проблемные классы.

**Действие:**
```python
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Загрузите confusion matrix из результатов обучения
# Или создайте заново на test выборке

# Анализируйте:
# - Какие классы путаются чаще всего
# - Есть ли классы, которые модель почти никогда не предсказывает
# - Есть ли классы, которые модель предсказывает слишком часто
```

**Если обнаружены проблемы:**
- Несбалансированные классы → используйте class weights
- Классы путаются → проверьте определение таргетов
- Низкая точность по классам 3, 4 → возможно, нужно больше данных для отскоков

### 7. Рекомендации по настройке порогов

Если распределение классов неправильное:

**Слишком много класса 0 (неопределенность):**
- Уменьшите `breakout_threshold` и `bounce_threshold`
- Или измените логику проверки в `_check_breakout()` и `_check_bounce()`

**Слишком мало классов 3, 4 (отскоки):**
- Уменьшите `bounce_threshold`
- Улучшите логику `_check_bounce()` (возможно, слишком строгие условия)

**Слишком много пробоев, мало отскоков:**
- Проверьте приоритет проверки (сначала отскок, затем пробой)
- Увеличьте `bounce_threshold` для более строгой фильтрации

### 8. Финальная проверка перед полным обучением

**Чеклист:**
- [ ] Распределение классов проверено и приемлемо
- [ ] Data leakage не обнаружен
- [ ] Генерация таргетов визуально проверена
- [ ] Тест на малой выборке прошел успешно
- [ ] Метрики на валидации приемлемы
- [ ] Confusion matrix проанализирована
- [ ] Все пути обновлены на `workspace/`
- [ ] TensorBoard/W&B настроены (если используются)
- [ ] Данные подготовлены и сохранены в `workspace/prepared/features/`

### 9. Команды для финального обучения

После всех проверок:

```bash
# Подготовка данных (12 месяцев)
python prepare_gold_data.py --months 12

# Обучение с мониторингом
python train_all_models.py --months 12 --use-wandb --wandb-project xauusd-ai-ea

# Или обучение одной модели
python train_model.py --use-wandb
```

### 10. Мониторинг во время обучения

**TensorBoard:**
```bash
python scripts/start_tensorboard.py
# Откройте http://localhost:6006
```

**W&B:**
- Откройте https://wandb.ai
- Выберите проект "xauusd-ai-ea"
- Следите за метриками в реальном времени

**Что отслеживать:**
- Val loss не должен расти (признак переобучения)
- Gap между train и val accuracy не должен увеличиваться
- Learning rate должен плавно изменяться

---

## Примечания

- **Не торопитесь!** Лучше потратить время на проверки, чем переобучать модель на неправильных данных
- **Сохраняйте результаты тестов** - они помогут понять, что изменилось
- **Документируйте изменения** - записывайте, какие пороги и параметры вы использовали

