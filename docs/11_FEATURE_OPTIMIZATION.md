# Оптимизация фичей и синхронизация

## Обзор

Руководство по оптимизации фичей для улучшения качества модели: анализ корреляции, удаление дубликатов, мониторинг аномалий и синхронизация фичей между обучением и применением.

## Объединенный анализ фичей (РЕКОМЕНДУЕТСЯ)

### Новый скрипт: `analyze_and_exclude_features.py`

**Объединяет анализ корреляции и комплексный анализ фичей** в один процесс, формируя список исключений с группировкой по причинам.

**Преимущества:**
- ✅ Единый процесс вместо двух отдельных скриптов
- ✅ Группировка фичей по причинам исключения с комментариями
- ✅ Автоматическое сохранение в `excluded_features.txt` с комментариями
- ✅ Убирает дубликаты между группами (фича попадает только в одну группу)
- ✅ Работает на объединенном датасете (train+val+test) для консистентности
- ✅ Приоритет причин: data leakage → корреляция → нули → пропуски → низкая важность

**Использование:**

```bash
# Базовый анализ на объединенном датасете (train+val+test)
python analyze_and_exclude_features.py

# С настройкой порогов
python analyze_and_exclude_features.py --correlation-threshold 0.90 --missing-threshold 85

# Без исключения по низкой важности
python analyze_and_exclude_features.py --no-low-importance

# Только анализ корреляции (быстрее)
python analyze_and_exclude_features.py --only-correlation
```

**Что анализируется:**

1. **Data Leakage фичи** - фичи, содержащие информацию о будущем
   - Паттерны: `future_return_*`, `max_future_return`, `direction_*`, `future_volatility_*`
   - **Приоритет**: Высший (всегда исключаются первыми)

2. **Высококоррелированные фичи** - корреляция > порога (по умолчанию 0.95)
   - Анализируется на объединенном датасете (train+val+test)
   - Удаляется менее приоритетная фича из пары
   - Базовые OHLC цены защищены и никогда не удаляются

3. **Фичи с 100% нулей** - полностью нулевые фичи
   - Не несут информации для модели
   - Определяется по статистике: `zeros == count` или `zeros_pct >= 99.99%`

4. **Фичи с большим процентом пропусков** - >90% пропусков (настраивается)
   - Слишком много пропущенных данных для использования
   - Настраивается через `--missing-threshold`

5. **Фичи с низкой важностью** - нижние 5% по combined_score (опционально)
   - Можно отключить через `--no-low-importance`
   - Настраивается через `--low-importance-percentile`
   - **Внимание**: Используйте с осторожностью, может удалить полезные фичи

**Формат выходного файла:**

Список сохраняется в `workspace/excluded_features.txt` с группировкой:

```
# ============================================================
# Data Leakage (фичи содержат информацию о будущем)
# Количество: 10
# ============================================================

future_return_1
future_return_5
max_future_return
...

# ============================================================
# Высокая корреляция (>0.95) с другими фичами
# Количество: 25
# ============================================================

distance_to_resistance_sigma
proximity_to_support_atr
...

# ============================================================
# 100% нулевых значений
# Количество: 3
# ============================================================

is_weekend
...
```

**Параметры:**

- `--train`, `--val`, `--test` - пути к CSV файлам (по умолчанию: workspace/prepared/features/gold_*.csv)
- `--correlation-threshold` - порог корреляции (по умолчанию: 0.95)
- `--missing-threshold` - порог процента пропусков (по умолчанию: 90.0)
- `--low-importance-percentile` - процентиль для низкой важности (по умолчанию: 5.0, 0 = отключить)
- `--no-low-importance` - не исключать фичи по низкой важности
- `--only-correlation` - выполнить только анализ корреляции (быстрее)
- `--output` - путь для сохранения списка (по умолчанию: workspace/excluded_features.txt)

**Рекомендуемый workflow:**

```bash
# 1. Подготовка данных
python prepare_gold_data.py --months 6 --balance-classes

# 2. Анализ и формирование списка исключений
python analyze_and_exclude_features.py

# 3. Проверка списка (опционально)
cat workspace/excluded_features.txt

# 4. Переподготовка данных с учетом исключений (если нужно)
# Фичи из excluded_features.txt будут автоматически исключены при обучении

# 5. Обучение модели
python train_all_models.py --encoder-only
```

**Примечание:** Фичи из `excluded_features.txt` автоматически исключаются при создании DataLoader'ов (см. `models/data_loader.py`).

**Как работает группировка:**

1. Фичи анализируются по всем критериям
2. Группируются по причинам исключения
3. Убираются дубликаты (фича попадает только в одну группу по приоритету)
4. Сохраняются в файл с комментариями-заголовками для каждой группы

**Приоритет причин (от высшего к низшему):**
1. Data Leakage (критично!)
2. Высокая корреляция
3. 100% нулей
4. Большой процент пропусков
5. Низкая важность (опционально)

---

## Анализ корреляции фичей (отдельный скрипт)

### Проблема мультиколлинеарности

Высокая корреляция между фичами (>0.95) может привести к:
- Избыточности информации
- Ухудшению обобщения модели
- Увеличению времени обучения
- Проблемам с интерпретацией

### Автоматический анализ

**Используйте объединенный скрипт `analyze_and_exclude_features.py`** (рекомендуется):

```bash
# Базовый анализ (порог корреляции 0.95)
python analyze_and_exclude_features.py

# С другим порогом корреляции
python analyze_and_exclude_features.py --correlation-threshold 0.90

# С настройкой других порогов
python analyze_and_exclude_features.py --correlation-threshold 0.90 --missing-threshold 85

# Без исключения по низкой важности
python analyze_and_exclude_features.py --no-low-importance
```

### Параметры скрипта

- `--train`, `--val`, `--test` - пути к CSV файлам (по умолчанию: `workspace/prepared/features/gold_*.csv`)
- `--correlation-threshold` - порог корреляции для исключения (по умолчанию: 0.95)
- `--missing-threshold` - порог процента пропусков (по умолчанию: 90.0)
- `--low-importance-percentile` - процентиль для низкой важности (по умолчанию: 5.0, 0 = отключить)
- `--no-low-importance` - не исключать фичи по низкой важности
- `--only-correlation` - выполнить только анализ корреляции (быстрее)

### Стратегия удаления

Скрипт автоматически выбирает фичи для удаления на основе приоритетов:

1. **Высокий приоритет** (оставляем):
   - Базовые ценовые фичи: `close`, `open`, `high`, `low`, `returns`, `log_returns`

2. **Средний приоритет**:
   - Технические индикаторы: `sma`, `ema`, `rsi`, `macd`, `atr`

3. **Низкий приоритет** (удаляем первыми):
   - Производные фичи: `lag`, `stat`, `tick`, `multitimeframe`, `position`, `shadow`

### Автоматическое удаление в pipeline

Включите автоматическое удаление в конфигурации:

```python
from config.feature_config import FeatureConfig

config = FeatureConfig(
    remove_correlated_features=True,  # Включить удаление
    correlation_threshold=0.95        # Порог корреляции
)
```

При подготовке данных высококоррелированные фичи будут удалены автоматически.

## Комплексный анализ фичей

### Обзор

**Рекомендуется использовать объединенный скрипт `analyze_and_exclude_features.py`**, который включает:
- Анализ корреляции
- Комплексный анализ фичей
- Автоматическое формирование списка исключений с группировкой по причинам

После подготовки данных рекомендуется провести анализ фичей. Это поможет понять их характеристики, важность и потенциальные проблемы перед оптимизацией обучения модели.

### Запуск анализа

#### Через full_pipeline.py

```bash
# Оптимизация фичей (объединенный анализ)
python full_pipeline.py --months 3 --remove-correlated

# С кастомным порогом корреляции
python full_pipeline.py --months 3 --remove-correlated --correlation-threshold 0.90

# Полный анализ (аналогично --remove-correlated)
python full_pipeline.py --months 3 --analyze-features
```

#### Отдельно

```bash
# Базовый анализ
python analyze_and_exclude_features.py

# С настройкой порогов
python analyze_and_exclude_features.py --correlation-threshold 0.90 --missing-threshold 85

# Без исключения по низкой важности
python analyze_and_exclude_features.py --no-low-importance
```

### Структура результатов

Все результаты сохраняются в `workspace/analysis-of-features/`:

```
workspace/analysis-of-features/
├── feature_statistics.csv              # Базовая статистика по фичам
├── feature_importance.csv              # Важность фичей (Mutual Info, F-score)
├── outliers_analysis.csv               # Анализ выбросов
├── feature_by_class_statistics.csv     # Статистика по классам
├── feature_analysis_report.html        # Сводный HTML отчет
└── plots/                              # Графики (если --generate-plots)
    ├── distributions/                  # Распределения фичей
    │   ├── feature1_distribution.png
    │   └── ...
    └── by_class/                       # Распределения по классам
        ├── feature1_by_class.png
        └── ...
```

### Интерпретация результатов

#### 1. feature_statistics.csv

Содержит базовую статистику по каждой фиче:

- **count** - количество непустых значений
- **missing** / **missing_pct** - количество и процент пропусков
- **zeros** / **zeros_pct** - количество и процент нулевых значений
- **mean, std, min, max, median, q25, q75** - описательная статистика
- **skewness** - асимметрия распределения
  - > 1: сильная правосторонняя асимметрия
  - < -1: сильная левосторонняя асимметрия
  - Близко к 0: симметричное распределение
- **kurtosis** - эксцесс (островершинность)
  - > 3: более островершинное, чем нормальное
  - < 3: более плосковершинное, чем нормальное
- **normality_p_value** - p-value теста нормальности (Shapiro-Wilk)
  - > 0.05: распределение близко к нормальному
  - < 0.05: распределение отличается от нормального

**Что искать:**
- Фичи с большим процентом пропусков (>10%) - могут требовать обработки
- Фичи с большим процентом нулей (>50%) - могут быть неинформативными
- Фичи с экстремальной асимметрией (|skewness| > 2) - могут требовать трансформации

#### 2. feature_importance.csv

Ранжирование фичей по важности для предсказания таргета:

- **mutual_info** - Mutual Information Score (0-1)
  - Выше = больше информации о таргете
  - > 0.1: высокая важность
  - 0.01-0.1: средняя важность
  - < 0.01: низкая важность
- **f_score** - ANOVA F-score
  - Выше = больше различий между классами
  - > 10: высокая дифференциация
  - 1-10: средняя дифференциация
  - < 1: низкая дифференциация
- **f_pvalue** - p-value F-теста
  - < 0.05: статистически значимые различия между классами
- **correlation_with_target** - корреляция с таргетом
  - > 0.3 или < -0.3: сильная корреляция
  - 0.1-0.3 или -0.3 до -0.1: умеренная корреляция
  - < 0.1: слабая корреляция
- **combined_score** - комбинированный score (0-100)
  - Среднее нормализованных Mutual Info и F-score
  - Используется для общего ранжирования

**Что искать:**
- Топ-20 фичей по combined_score - наиболее важные для модели
- Фичи с низким combined_score (< 1) - кандидаты на удаление
- Фичи с высокой корреляцией с таргетом - особенно важны

#### 3. outliers_analysis.csv

Анализ выбросов в фичах:

- **iqr_outliers** / **iqr_outliers_pct** - выбросы по методу IQR
  - Выбросы: значения за пределами Q1 - 1.5*IQR и Q3 + 1.5*IQR
- **zscore_outliers** / **zscore_outliers_pct** - выбросы по Z-score
  - Выбросы: значения с |z-score| > 3

**Что искать:**
- Фичи с большим процентом выбросов (>10%) - могут требовать обработки
- Выбросы могут быть:
  - Реальными аномалиями (требуют удаления или обработки)
  - Важными экстремальными значениями (не удалять)

**Рекомендации:**
- Если выбросы > 20% и фича не важна (low combined_score) - рассмотреть удаление
- Если выбросы > 20% и фича важна - использовать robust scaler или clipping

#### 4. feature_by_class_statistics.csv

Статистика распределения фичей по классам:

Для каждой фичи и каждого класса:
- **count, mean, std, median, min, max** - статистика по классу
- **differentiation_cv** - коэффициент вариации между классами
  - Выше = больше различий между классами
  - > 0.2: хорошая дифференциация
  - < 0.1: слабая дифференциация

**Что искать:**
- Фичи с высоким differentiation_cv - хорошо различают классы
- Фичи с низким differentiation_cv - плохо различают классы (кандидаты на удаление)

#### 5. feature_analysis_report.html

Интерактивный HTML отчет с:
- Общей информацией о фичах
- Топ-20 важных фичей
- Топ-10 фичей с выбросами
- Рекомендациями по использованию

Откройте в браузере для удобного просмотра.

### Использование результатов для оптимизации обучения

#### При переобучении

1. **Проверьте фичи с выбросами:**
   - Если много фичей с выбросами > 10% - увеличьте dropout
   - Рассмотрите удаление фичей с выбросами > 20% и низкой важностью

2. **Проверьте важность фичей:**
   - Если много фичей с низкой важностью (< 1% combined_score) - рассмотрите их удаление
   - Сфокусируйтесь на топ-50 фичах по combined_score

3. **Проверьте распределения:**
   - Фичи с экстремальной асимметрией могут требовать трансформации
   - Используйте log-transform для правосторонних распределений

#### При недообучении

1. **Проверьте дифференциацию классов:**
   - Если фичи плохо различают классы (low differentiation_cv) - улучшите фичи
   - Используйте фичи с высоким differentiation_cv

2. **Проверьте важность фичей:**
   - Убедитесь, что используете топ-важные фичи
   - Рассмотрите добавление новых фичей на основе важных паттернов

#### Рекомендации по настройке параметров

На основе анализа фичей:

**Если много выбросов (>10% в топ фичах):**
```bash
python full_pipeline.py --months 3 \
  --dropout 0.2 \
  --weight-decay 1e-4 \
  --analyze-features
```

**Если фичи хорошо дифференцируют классы:**
```bash
python full_pipeline.py --months 3 \
  --dropout 0.15 \
  --use-class-weights \
  --analyze-features
```

**Если много фичей с низкой важностью:**
- Рассмотрите удаление фичей с combined_score < 1
- Сфокусируйтесь на топ-100 фичах

### Примеры интерпретации

#### Пример 1: Фича с высокой важностью и выбросами

```
feature: rsi_14
mutual_info: 0.15 (высокая)
f_score: 25.3 (высокая)
combined_score: 85.2 (топ-5)
iqr_outliers_pct: 12.5% (много выбросов)
```

**Интерпретация:** Важная фича, но с выбросами. Рекомендации:
- Не удалять (высокая важность)
- Использовать robust scaler или clipping для выбросов
- Увеличить dropout для регуляризации

#### Пример 2: Фича с низкой важностью и выбросами

```
feature: some_derived_feature
mutual_info: 0.002 (низкая)
f_score: 0.5 (низкая)
combined_score: 0.8 (низкая)
iqr_outliers_pct: 18.3% (много выбросов)
```

**Интерпретация:** Неважная фича с выбросами. Рекомендации:
- Кандидат на удаление
- Не добавляет ценности модели
- Выбросы могут мешать обучению

#### Пример 3: Фича с хорошей дифференциацией классов

```
feature: price_to_sma_20
differentiation_cv: 0.35 (высокая)
combined_score: 72.1 (высокая)
```

**Интерпретация:** Отличная фича для классификации. Рекомендации:
- Обязательно использовать
- Может быть ключевой для различения классов
- Рассмотреть создание похожих фичей

## Мониторинг аномалий

### Проблема выхода за диапазон обучения

Если цена выходит за диапазон, на котором обучалась модель, входные значения могут стать аномальными (выходят за 3σ от обучающей выборки).

### Автоматический мониторинг

Система автоматически отслеживает аномалии во время бэктестинга:

1. **Проверка аномалий**: для каждого сигнала проверяется, выходят ли значения за 3σ
2. **Снижение уверенности**: если обнаружена аномалия, уверенность модели снижается пропорционально
3. **Пропуск сигналов**: если >50% фичей аномальны, сигнал пропускается

### Статистика аномалий

После бэктестинга выводится статистика:

```
⚠️  Мониторинг аномалий:
  Всего проверок: 1000
  Обнаружено аномалий: 45 (4.5%)
  Сигналов пропущено: 12
  Уверенность снижена: 33 раз
```

### Настройка порога

Порог аномалий можно изменить в `Backtester`:

```python
backtester = Backtester(
    model_path='workspace/models/checkpoints/encoder_model.pth',
    scaler_path='workspace/prepared/scalers/feature_scaler_encoder.pkl'
)
backtester.anomaly_threshold = 2.5  # 2.5σ вместо 3σ
```

## Рекомендации

### Для анализа корреляции

1. **Регулярно проверяйте корреляцию** после добавления новых фичей
2. **Используйте порог 0.95** для нейросетей (можно снизить до 0.90 для линейных моделей)
3. **Визуализируйте корреляции** для понимания структуры данных
4. **Автоматизируйте удаление** в pipeline для новых данных

### Для мониторинга аномалий

1. **Расширяйте обучающую выборку** - включайте периоды с разными ценовыми уровнями
2. **Используйте RobustScaler** вместо StandardScaler для устойчивости к выбросам
3. **Мониторьте статистику** - высокая доля аномалий (>10%) указывает на проблему
4. **Настройте порог** под ваши данные и требования

### Для улучшения обобщения

1. **Используйте относительные фичи** - процентные изменения вместо абсолютных
2. **Нормализуйте данные** - StandardScaler или RobustScaler
3. **Удаляйте дубликаты** - высококоррелированные фичи
4. **Мониторьте аномалии** - отслеживайте выход за диапазон обучения

## Примеры использования

### Анализ корреляции перед обучением

#### Вариант 1: Автоматически в full_pipeline.py (рекомендуется)

```bash
# Автоматическое удаление коррелированных фичей в полном цикле
python full_pipeline.py --months 12 --remove-correlated

# С кастомным порогом корреляции
python full_pipeline.py --months 12 --remove-correlated --correlation-threshold 0.90
```

#### Вариант 2: Вручную (для детального анализа)

```bash
# 1. Подготовка данных
python prepare_gold_data.py --months 12

# 2. Оптимизация фичей (объединенный анализ)
python analyze_and_exclude_features.py --correlation-threshold 0.95

# 4. Обучение на очищенных данных
python train_all_models.py
```

### Автоматическое удаление в full_pipeline.py

Для автоматизации процесса удаления высококоррелированных фичей можно использовать `full_pipeline.py`:

```bash
# Автоматическое удаление с порогом 0.95 (по умолчанию)
python full_pipeline.py --months 12 --remove-correlated

# С настройкой порога корреляции
python full_pipeline.py --months 12 --remove-correlated --correlation-threshold 0.90
```

#### Как это работает

**Важно**: Анализ корреляций выполняется на **объединенном датасете** (train+val+test), что гарантирует:
- ✅ **Одинаковый набор фичей** во всех трех файлах
- ✅ **Консистентность данных** для обучения и валидации
- ✅ **Отсутствие ошибок** при загрузке данных в модель

**Процесс автоматизации:**

1. **Анализ на объединенном датасете**
   - Все три файла (train, val, test) объединяются для анализа
   - Находятся высококоррелированные пары фичей
   - Определяется список фичей для удаления

2. **Применение удаления**
   - Одинаковый список фичей удаляется из всех трех файлов
   - Создаются резервные копии оригинальных файлов (`*_backup.csv`)

3. **Сохранение результатов**
   - Список удаленных фичей: `workspace/prepared/features/features_to_remove_threshold_X.XX.csv`
   - Таблицы анализа корреляций: `workspace/prepared/features/highly_correlated_pairs_threshold_X.XX.csv`
   - Статистика анализа: `workspace/prepared/features/correlation_analysis_stats_threshold_X.XX.csv`

4. **Создание документации**
   - Автоматически создается документация по оставшимся фичам
   - Сохраняется в `workspace/prepared/features/features_documentation_after_correlation_removal.json/.md`

### Мониторинг аномалий в бэктестинге

```python
from trading.backtester import Backtester

backtester = Backtester(
    model_path='workspace/models/checkpoints/encoder_model.pth',
    scaler_path='workspace/prepared/scalers/feature_scaler_encoder.pkl'
)

# Бэктестинг с автоматическим мониторингом аномалий
results = backtester.backtest(test_df)

# Статистика аномалий доступна в:
print(backtester.anomaly_stats)
```

## Синхронизация фичей между обучением и применением

### Проблема

При разных настройках подготовки данных (например, с/без удаления коррелированных фичей) могут получиться разные наборы фичей. Это критично для корректной работы модели.

### Решение

Система автоматически сохраняет и проверяет соответствие фичей:

1. **При обучении** (`models/data_loader.py`):
   - Список фичей сохраняется в scaler файл
   - Сохраняются метаданные о настройках подготовки
   - Сохраняется hash фичей для проверки целостности

2. **При применении** (`trading/backtester.py`):
   - Автоматическая валидация фичей при загрузке scaler
   - Проверка наличия всех необходимых фичей
   - Предупреждения о лишних фичах
   - Использование только сохраненных фичей в правильном порядке

### Метаданные в scaler

Каждый scaler файл содержит:

```python
{
    'scaler': StandardScaler,
    'feature_columns': ['close', 'returns', 'rsi_14', ...],  # Список фичей
    'feature_stats': {...},  # Статистика для мониторинга аномалий
    'metadata': {
        'training_months': 12,
        'model_type': 'encoder',
        'num_features': 608,
        'preparation_config': {
            'remove_correlated_features': True,
            'correlation_threshold': 0.95
        },
        'feature_columns_hash': 1234567890,  # Hash для проверки
        'saved_at': '2025-11-24T23:30:00'
    }
}
```

### Валидация фичей

#### Автоматическая валидация

При бэктестинге валидация происходит автоматически:

```python
backtester = Backtester(
    model_path='workspace/models/checkpoints/encoder_model.pth',
    scaler_path='workspace/prepared/scalers/feature_scaler_encoder.pkl'
)
# Валидация происходит автоматически при вызове backtest()
results = backtester.backtest(test_df)
```

#### Ручная валидация

Используйте скрипт `validate_features.py`:

```bash
# Валидация test данных
python validate_features.py

# Валидация train данных
python validate_features.py --data workspace/prepared/features/gold_train.csv

# С другим scaler
python validate_features.py --scaler workspace/prepared/scalers/feature_scaler_timeseries.pkl
```

#### Программная валидация

```python
from utils.feature_validator import validate_dataframe_features, print_validation_report

result = validate_dataframe_features(
    df=test_df,
    scaler_path='workspace/prepared/scalers/feature_scaler_encoder.pkl'
)

print_validation_report(result)
```

### Что происходит при несоответствии

1. **Отсутствующие фичи** → `ValueError`:
   ```
   ❌ ОШИБКА: В DataFrame отсутствуют фичи, которые использовались при обучении:
      Отсутствуют: ['feature1', 'feature2', ...]
      Всего отсутствует: 15 из 608
   ```

2. **Лишние фичи** → Предупреждение (игнорируются):
   ```
   ⚠️  ПРЕДУПРЕЖДЕНИЕ: В DataFrame есть фичи, которых не было при обучении:
      Лишние фичи: ['extra_feature1', ...]
      Эти фичи будут проигнорированы
   ```

3. **Неправильный порядок** → Автоматически исправляется

### Рекомендации для разных экспериментов

#### Вариант 1: Версионирование файлов

Используйте разные имена для разных экспериментов:

```python
# Эксперимент 1: без удаления коррелированных
scaler_path = 'workspace/prepared/scalers/feature_scaler_encoder_v1.pkl'
model_path = 'workspace/models/checkpoints/encoder_model_v1.pth'

# Эксперимент 2: с удалением коррелированных
scaler_path = 'workspace/prepared/scalers/feature_scaler_encoder_v2_corr.pkl'
model_path = 'workspace/models/checkpoints/encoder_model_v2_corr.pth'
```

#### Вариант 2: Использование метаданных

Проверяйте метаданные перед использованием:

```python
from utils.feature_validator import load_scaler_metadata

metadata = load_scaler_metadata('workspace/prepared/scalers/feature_scaler_encoder.pkl')
if metadata.get('preparation_config', {}).get('remove_correlated_features'):
    print("Эта модель обучена с удалением коррелированных фичей")
```

#### Вариант 3: Документирование

Ведите журнал экспериментов:

```
experiments/
├── exp1_no_corr/
│   ├── model.pth
│   ├── scaler.pkl
│   └── config.txt
└── exp2_with_corr/
    ├── model.pth
    ├── scaler.pkl
    └── config.txt
```

### Сравнение scaler файлов

Используйте утилиту для сравнения:

```python
from utils.feature_validator import compare_scalers

compare_scalers(
    'workspace/prepared/scalers/feature_scaler_encoder_v1.pkl',
    'workspace/prepared/scalers/feature_scaler_encoder_v2.pkl'
)
```

## Экспорт документации по фичам

### Автоматический экспорт

После обучения модели автоматически создается документация по всем фичам:

- **JSON формат**: `workspace/models/checkpoints/{model_type}_model_features_documentation.json`
- **Markdown формат**: `workspace/models/checkpoints/{model_type}_model_features_documentation.md`

### Ручной экспорт

Для существующей модели:

```bash
# Экспорт для encoder модели
python export_features_doc.py --model-type encoder

# Экспорт для timeseries модели
python export_features_doc.py --model-type timeseries

# С указанием пути к scaler
python export_features_doc.py --scaler workspace/prepared/scalers/feature_scaler_encoder.pkl
```

### Что включает документация

Для каждого фича:
- **Название** и **описание**
- **Формула расчета** (если удалось извлечь из кода)
- **Категория** (ценовые, технические индикаторы, волатильность и т.д.)
- **Источник** (файл и функция, которая создает фичу)
- **Статистика** из обучающей выборки (mean, std)

### Преимущества

- **Не запутаетесь**: каждая модель имеет свою документацию
- **Легко передавать**: получатель видит, как рассчитываются фичи
- **Версионирование**: документация сохраняется вместе с моделью
- **Отслеживание изменений**: можно сравнить документации разных версий

## Следующие шаги

1. Проведите анализ корреляции на ваших данных
2. Удалите высококоррелированные фичи
3. **Проведите комплексный анализ фичей** для понимания их характеристик
4. Переобучите модель на очищенных данных
5. **Проверьте соответствие фичей** перед применением модели
6. Сравните результаты до и после оптимизации
7. Настройте мониторинг аномалий под ваши требования
8. **Ведите журнал экспериментов** с разными настройками
9. **Используйте документацию по фичам** для отслеживания изменений
10. **Используйте результаты анализа фичей** для настройки параметров регуляризации при переобучении

