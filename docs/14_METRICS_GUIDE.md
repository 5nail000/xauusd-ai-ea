# Руководство по интерактивным метрикам обучения

Это руководство описывает использование TensorBoard и Weights & Biases (W&B) для мониторинга процесса обучения моделей.

## Содержание

1. [TensorBoard](#tensorboard)
2. [Weights & Biases](#weights--biases)
3. [Сравнение инструментов](#сравнение-инструментов)
4. [Рекомендации](#рекомендации)

## TensorBoard

### Установка

TensorBoard устанавливается автоматически с зависимостями проекта:

```bash
pip install tensorboard>=2.10.0
```

### Использование

#### Автоматический запуск

Используйте скрипт для автоматического запуска TensorBoard:

```bash
python scripts/start_tensorboard.py
```

Скрипт автоматически найдет последнюю директорию с логами в `workspace/models/logs/` и запустит TensorBoard.

#### Ручной запуск

Если нужно указать конкретную директорию:

```bash
tensorboard --logdir workspace/models/logs/encoder_20251126_123456 --port 6006
```

Или для просмотра всех экспериментов:

```bash
tensorboard --logdir workspace/models/logs/ --port 6006
```

#### Доступ через браузер

После запуска TensorBoard будет доступен по адресу:

```
http://localhost:6006
```

#### Доступ через SSH туннель (для удаленного сервера)

Если обучение происходит на удаленном сервере (например, Paperspace), используйте SSH туннель:

```bash
ssh -L 6006:localhost:6006 user@paperspace.com
```

Затем откройте `http://localhost:6006` на локальной машине.

### Что логируется

TensorBoard автоматически логирует следующие метрики:

- **Loss/Train_Batch** - Loss на каждом батче обучающей выборки
- **Loss/Train** - Средний loss по эпохам на обучающей выборке
- **Loss/Val** - Средний loss по эпохам на валидационной выборке
- **Accuracy/Train_Batch** - Accuracy на каждом батче
- **Accuracy/Train** - Accuracy по эпохам на обучающей выборке
- **Accuracy/Val** - Accuracy по эпохам на валидационной выборке
- **Learning_Rate** - Изменение learning rate по эпохам

### Интерпретация метрик

1. **Loss кривые:**
   - Train loss должен постепенно уменьшаться
   - Val loss должен следовать за train loss
   - Если val loss начинает расти, а train loss продолжает падать - это признак переобучения

2. **Accuracy кривые:**
   - Обе кривые должны расти
   - Gap между train и val accuracy не должен быть слишком большим (>10-15%)

3. **Learning Rate:**
   - Должен плавно изменяться согласно scheduler
   - Резкие скачки могут указывать на проблемы

## Weights & Biases

### Установка

```bash
pip install wandb>=0.15.0
```

### Первоначальная настройка

1. Зарегистрируйтесь на [wandb.ai](https://wandb.ai)
2. Войдите в аккаунт:

```bash
wandb login
```

Введите API ключ с сайта wandb.ai.

### Использование

#### Включение W&B при обучении

Используйте флаг `--use-wandb`:

```bash
python train_model.py --use-wandb
```

Или для train_all_models.py:

```bash
python train_all_models.py --use-wandb --wandb-project my-project
```

#### Параметры

- `--use-wandb` - Включить логирование в W&B
- `--wandb-project` - Название проекта (по умолчанию: "xauusd-ai-ea")

### Что логируется

W&B логирует те же метрики, что и TensorBoard:

- `train_loss` - Loss на обучающей выборке
- `val_loss` - Loss на валидационной выборке
- `train_acc` - Accuracy на обучающей выборке
- `val_acc` - Accuracy на валидационной выборке
- `lr` - Learning rate

Также автоматически сохраняются:
- Конфигурация модели
- Гиперпараметры обучения
- Информация об устройстве (CPU/GPU)

### Преимущества W&B

1. **Облачное хранение** - Все метрики доступны онлайн
2. **Сравнение экспериментов** - Легко сравнивать разные запуски
3. **Автоматические графики** - Визуализация трендов
4. **Командная работа** - Общий доступ к результатам
5. **Интеграция с другими инструментами** - Поддержка многих ML фреймворков

## Сравнение инструментов

| Характеристика | TensorBoard | W&B |
|---------------|-------------|-----|
| Установка | Локальная | Облачная + локальная |
| Хранение | Локально | Облако |
| Доступ | Локальный/SSH | Онлайн |
| Сравнение экспериментов | Вручную | Автоматически |
| Командная работа | Сложно | Легко |
| Бесплатный план | Да | Да (с ограничениями) |

## Рекомендации

### Когда использовать TensorBoard

- Локальная разработка и отладка
- Когда нужен полный контроль над данными
- Для быстрого просмотра метрик во время обучения
- Когда нет интернета или нужна приватность

### Когда использовать W&B

- Долгосрочное хранение результатов
- Сравнение множества экспериментов
- Командная работа над проектом
- Публикация результатов
- Когда нужен доступ к метрикам с любого устройства

### Комбинированное использование

Можно использовать оба инструмента одновременно:

```bash
python train_model.py --use-wandb
```

TensorBoard логи создаются всегда, W&B включается опционально.

## Полезные команды

### Просмотр всех экспериментов в TensorBoard

```bash
tensorboard --logdir workspace/models/logs/
```

### Остановка TensorBoard

Нажмите `Ctrl+C` в терминале, где запущен TensorBoard.

### Просмотр экспериментов в W&B

Откройте [wandb.ai](https://wandb.ai) и выберите ваш проект.

### Синхронизация W&B офлайн

Если обучение происходило без интернета:

```bash
wandb sync workspace/models/logs/
```

## Дополнительные ресурсы

- [TensorBoard документация](https://www.tensorflow.org/tensorboard)
- [W&B документация](https://docs.wandb.ai)
- [W&B для PyTorch](https://docs.wandb.ai/guides/integrations/pytorch)

